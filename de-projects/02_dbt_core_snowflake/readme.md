# Deploy Analytics Engineering pipelines with DBT Core, Snowflake and Docker

## Objectives

1. Learn to deploy a functional dbt platform from scratch with virtual environment
2. Setup reliable transformation data pipelines running on schedule
3. Pack pre-built system in docker container to make it work

[This tutorial](https://quickstarts.snowflake.com/guide/data_teams_with_dbt_core/index.html#0) will be used as a pattern to follow yet deploy our own database.

## Key Terms

**DBT** is a command-line tool that enables data analysts and engineers to transform data in their warehouse more effectively. It allows users to write modular SQL queries, which it then runs on their warehouse in the correct order with the ability to test and document the data.

**Snowflake** is a cloud-based data warehousing platform that allows businesses to store and analyze large amounts of data. Its unique architecture separates storage and computing, enabling scalable and cost-effective data processing.

**Docker** is a platform that uses containerization technology to enable developers to package applications and their dependencies into a standardized unit for software development. Containers are isolated environments that can run across different computing environments consistently.

**Github** is a web-based platform for version control and collaboration. It allows developers to store, manage, and track changes to their code using the Git system. GitHub also offers features like code review, project management, and team collaboration.

## Prerequisites

1. Snowflake Trial (valid for 30 days). You can start from a [Free Trial](https://signup.snowflake.com/)
3. Installed Financial & Economic Essentials [database](https://app.snowflake.com/marketplace/listing/GZTSZAS2KF7/cybersyn-inc-financial-economic-essentials?available=installed)
2. Knowledge of basic IDE (i.e. VSCode) + knowing how to set up virtual envoronments
3. Knowledge of [dbt fundamentals](https://courses.getdbt.com/courses/fundamentals)
4. VSCode
5. Python v 3.11 or less 
5. Registered github account
6. Docker fundamentals [knowledge](https://www.youtube.com/watch?v=pg19Z8LL06w&t=1282)

## Implementation

1. Setup git repo
2. Setup virtual environment
3. Install dbt
4. Initiate integration between dbt & snowflake
5. Validate perfromance

## Materials:
- [Snowflake Trial](link)
- [Snowflake dbt Core tutorial](https://quickstarts.snowflake.com/guide/data_teams_with_dbt_core/index.html#0)

## Additional materials:
- [Recommended udemy course on docker](https://www.udemy.com/course/docker-ru/)
- [DBT Macros](https://courses.getdbt.com/courses/jinja-macros-packages)
- [DBT Best Practice](https://docs.getdbt.com/guides/legacy/best-practices)

All discussions and weekly meetings will be in the Discord channel - **data-engineering-projects**.



